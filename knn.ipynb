{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KNN\n",
        "In this notebook we have two news datasets, one with categories labeled and one without labels. We use Elasticsearch to index the dataset with labels and further implement K-Nearest Neighbors algorithm to classify and label the unlabeled dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FRQkBOypdLoz"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch import helpers\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing and Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we define a `mapping` to specify fields their types so we can index the documents accordingly. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WXjF6F5LdLpP"
      },
      "outputs": [],
      "source": [
        "mapping = { \n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "          \"content\": {\n",
        "            \"type\": \"text\"\n",
        "          },\n",
        "            \"category\":{\n",
        "                \"type\": \"keyword\"\n",
        "            },\n",
        "            \"vec\":{\n",
        "                \"type\": \"dense_vector\",\n",
        "                \"dims\": 200,\n",
        "                \"index\": True,\n",
        "                \"similarity\": \"cosine\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LlomFmlqdLpQ"
      },
      "outputs": [],
      "source": [
        "es = Elasticsearch(\"http://localhost:9200\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Svhk9olodLpR"
      },
      "outputs": [],
      "source": [
        "index_name = 'ir_knn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8oAzzl94dLpS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Amin\\AppData\\Local\\Temp/ipykernel_6336/1371288542.py:6: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
            "  es.indices.create(index=index_name, body=mapping)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'ir_knn'})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Delete index if one does exist\n",
        "if es.indices.exists(index=index_name):\n",
        "    es.indices.delete(index=index_name)\n",
        "\n",
        "# Create index\n",
        "es.indices.create(index=index_name, body=mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we preprocess our labeled news articles and come up with a list of tokens for each one of them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from preprocess import Preprocess\n",
        "\n",
        "df = pd.read_excel('./data/IR01_3_test_4k.xlsx')\n",
        "\n",
        "preprocess = Preprocess()\n",
        "\n",
        "df_processed = df\n",
        "\n",
        "df_processed['content'] = df['content'].apply(preprocess.normalize)\n",
        "df_processed['content'] = df_processed['content'].apply(preprocess.tokenize)\n",
        "df_processed['content'] = df_processed['content'].apply(preprocess.stem)\n",
        "df_processed['content'] = df_processed['content'].apply(preprocess.redact_stops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the `embeding` module we create a numerical vector representation of each news articles (documents) and store them in `doc_vectors`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There is no pre-trained model. Going to train a model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Amin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from  embeding import DocToVec\n",
        "\n",
        "dataset = [[] for _ in range(df.shape[0])]\n",
        "\n",
        "for index, row in df_processed.iterrows():\n",
        "    dataset[index] = row['content'].split(\" \")\n",
        "\n",
        "doc2vec = DocToVec(dataset , vec_size = 200 , model_path = './data/word2vec.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_vectors = []\n",
        "for i in range(df.shape[0]):\n",
        "  doc_vectors.append(doc2vec.embed(dataset[i])) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a function to later on preprocess and filter every new articles that we wanna label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_doc(content):\n",
        "    content = preprocess.normalize(content)\n",
        "    content = preprocess.tokenize(content)\n",
        "    content = preprocess.stem(content)\n",
        "    return preprocess.redact_stops(content).split(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_tmp = []\n",
        "for index, row in df_processed.iterrows():\n",
        "    doc = dict()\n",
        "    doc['content'] = row['content']\n",
        "    doc['vec'] = list(doc_vectors[index])\n",
        "    doc['category'] = row['category']\n",
        "    data_tmp.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RgSbNxq7dLpU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4022, [])\n"
          ]
        }
      ],
      "source": [
        "data_bulk = [\n",
        "    {\n",
        "        \"_index\" : index_name,\n",
        "        \"_id\" : i + 1,\n",
        "        \"_source\": data_tmp[i]\n",
        "    }\n",
        "    for i in range(len(data_tmp))\n",
        "]\n",
        "resp = helpers.bulk(\n",
        "  es,\n",
        "  data_bulk,\n",
        "  index = index_name\n",
        ")\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Labeling\n",
        "Here we load our test dataset and iterate through them. Each time we make a vector representation of that document and then perform a **KNN Search** of 10 nearest neighbors in our index for that document. From these neighbors we find the most common category of news amongst them and label our unlabeled document with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LttqgmRFdLpV"
      },
      "outputs": [],
      "source": [
        "test_dataset = pd.read_excel(\"./data/IR01_3_46k.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def doc_to_vec(content):\n",
        "    content_processed = filter_doc(content)\n",
        "    return list(doc2vec.embed(content_processed))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\AUT\\8th_term\\Information Retrieval\\FinalProject\\elasticsearch-news-engine\\embeding.py:87: RuntimeWarning: invalid value encountered in true_divide\n",
            "  vec /= sum_weights\n"
          ]
        }
      ],
      "source": [
        "test_dataset['category'] = 'NaN'\n",
        "for index, row in test_dataset.iterrows():\n",
        "    res = []\n",
        "    vec = doc_to_vec(row['content'])    \n",
        "    try:\n",
        "        resp = es.knn_search(index=index_name,knn={\n",
        "        \"field\": \"vec\",\n",
        "        \"query_vector\": vec,\n",
        "        \"k\": 10,\n",
        "        \"num_candidates\": 100\n",
        "        }\n",
        "        ,source=['content','category'],)\n",
        "\n",
        "        for result in resp['hits']['hits']:\n",
        "            res.append(result['_source']['category'])\n",
        "        category = max(set(res), key=res.count)\n",
        "\n",
        "    except:\n",
        "        category = 'Others'\n",
        "    \n",
        "    test_dataset.at[index,'category'] = category\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "del test_dataset['Unnamed: 0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer = pd.ExcelWriter('./data/IR01_3_46k_classified_3.xlsx')\n",
        "test_dataset.to_excel(writer)\n",
        "writer.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indexing Labeled Documents\n",
        "We index our newly labeled documents and then perform a boolean query search to make sure that we have the right categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "classified_index_name = 'classified_index'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "if es.indices.exists(index=classified_index_name):\n",
        "    es.indices.delete(index=classified_index_name)\n",
        "\n",
        "    es.indices.create(index=classified_index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from elasticsearch.helpers import bulk\n",
        "\n",
        "def bulk_sync():\n",
        "    actions = [\n",
        "        {\n",
        "            '_index': classified_index_name,\n",
        "            '_id':doc_id,\n",
        "            '_source': doc.to_dict()\n",
        "        } for doc_id,doc in test_dataset.iterrows()\n",
        "    ]\n",
        "    bulk(es, actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "bulk_sync()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_query(text, category):\n",
        "    body ={\n",
        "    \"query\":{  \n",
        "        \"bool\": {\n",
        "            \"must\": [\n",
        "                { \"match\": { \"category\": category }},\n",
        "                { \"match\": { \"content\": text }}\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "    }\n",
        "    \n",
        "    return body"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "queries = [\n",
        "    (\"نتایج مسابقات لیگ برتر ایران\", \"sport\"),\n",
        "    (\"تحریم های آمریکا\", \"economy\"),\n",
        "    (\"ویروس کرونا\", \"health\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Amin\\AppData\\Local\\Temp/ipykernel_6336/2119087745.py:3: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
            "  res_search = es.search(index=classified_index_name, body=get_query(q[0], q[1]), explain=True)\n"
          ]
        }
      ],
      "source": [
        "query_results = []\n",
        "for q in queries:\n",
        "    res_search = es.search(index=classified_index_name, body=get_query(q[0], q[1]), explain=True)\n",
        "    query_results.append(dict(res_search))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('نتایج مسابقات لیگ برتر ایران', 'sport')\n",
            "https://www.farsnews.ir/news/13991127001103/زمان-برگزاری-مسابقات-روز-آخر-لیگ-هندبال-تغییر-کرد\tsport\n",
            "-----\n",
            "https://www.farsnews.ir/news/13991203000693/پورمحمد-نباید-صدر-جدول-را-به-راحتی-از-دست-بدهیم-وضعیت-برگزاری-و-داوری\tsport\n",
            "-----\n",
            "https://www.farsnews.ir/news/13991215000268/قهرمانی-لیگ-برتر-کاراته-به-مس-رفسنجان-رسید\tsport\n",
            "-----\n",
            "https://www.farsnews.ir/news/13991113000405/ولیان-هدف‌مان-پشتوانه‌سازی-برای-هندبال-است\tsport\n",
            "-----\n",
            "https://www.farsnews.ir/news/13991113001111/لیگ-برتر-والیبال|-نتایج-کامل-هفته-بیست‌وپنجم-تثبیت-جایگاه-بالانشین‌ها\tsport\n",
            "-----\n",
            "https://www.farsnews.ir/news/13991105000678/گروه‌بندی-مرحله-سوم-لیگ-برتر-هندبال-مشخص-شد\tsport\n",
            "-----\n",
            "https://www.farsnews.ir/news/13991126000645/لیگ‌برتر-تنیس-روی-میز|-صعود-یاران-عالمیان-و-شهرداری-کرج-به-نیمه-نهایی\tsport\n",
            "-----\n",
            "https://www.farsnews.ir/news/13991221000389/دورنهایی-فوتبال-بانوان|-شکست-بم-در-نصف-جهان-سیرجان-به-صدر-صعود-کرد\tsport\n",
            "-----\n",
            "https://www.isna.ir/news/98030401704/کولاکوویچ-می-توان-به-حضور-در-جمع-۶-تیم-لیگ-ملت-ها-امیدوار-بود\tsport\n",
            "-----\n",
            "https://www.farsnews.ir/news/13991217000586/مرحله-نهایی-لیگ-برتر-فوتسال|-ازمدعیان-کسب-قهرمانی-دیروز-تا-مدعیان\tsport\n",
            "-----\n",
            "----------------------------\n",
            "('تحریم های آمریکا', 'economy')\n",
            "https://www.farsnews.ir/news/13990708000942/دلار-۳۰-هزار-تومانی-و-تورم-بالا-جدیدترین-دستاورد-برجام-نتیجه-اعتماد\teconomy\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990907000144/رشد-4-درصدی-اقتصاد-ایران-با-لغو-تحریم‌ها-با-وجود-تحریم‌ها-هم-اقتصاد\teconomy\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990514000951/دانمارک-ادامه-ساخت-خط-لوله-نورد-استریم-2-بلامانع-است\teconomy\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990406000265/ادامه-صادرات-نفت-ایران-از-دریای-عمان-در-صورت-بستن-تنگه-هرمز\teconomy\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990909000812/ازسرگیری-احداث-خط-لوله-پروژه-نورد-استریم-2-علیرغم-تحریم‌های-آمریکا\teconomy\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990719000629/بانک‌های-تحریم‌شده-قبلا-هم-تحریم-بودند\teconomy\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990328000531/کاهش-صادرات-نفت-ونزوئلا-به-کمترین-میزان-0-سال-گذشته\teconomy\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990321000701/منابع-ما-بطور-غیرقانونی-در-بانک‌های-کره‌-مسدود-شده-است-خلف-وعده\teconomy\n",
            "-----\n",
            "https://www.farsnews.ir/news/14000116000240/لزوم-مرتفع-شدن-محدودیت‌ها-و-موانع-در-بنادر-چین-برای-ناوگان-ملی\teconomy\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990902000242/2-راهبرد-توسعه-همکاری-ارزی-با-اتحادیه-اقتصادی-اوراسیا\teconomy\n",
            "-----\n",
            "----------------------------\n",
            "('ویروس کرونا', 'health')\n",
            "https://www.isna.ir/news/98120605091/کلید-رفع-کرونا-ویروس-فرهنگی-است-ایجاد-گیت-تست-تب-سنجی-در-مبادی\thealth\n",
            "-----\n",
            "https://www.isna.ir/news/98120302332/موارد-مشکوک-به-کرونا-ویروس-در-بابل-هنوز-تایید-نشده-است\thealth\n",
            "-----\n",
            "https://www.isna.ir/news/99062216073/۵-ویروس-تنفسی-که-از-مهر-ماه-شایع-می-شود\thealth\n",
            "-----\n",
            "https://www.isna.ir/news/98121007867/دستور-قضائی-برای-پلمب-قلیان-سراهای-فعال-در-مازندران\thealth\n",
            "-----\n",
            "https://www.isna.ir/news/99120200571/شروع-موج-چهارم-کرونا-با-علائمی-شبیه-سرماخوردگی\thealth\n",
            "-----\n",
            "https://www.isna.ir/news/99091813630/احتمال-ابتلای-شدیدتر-بهبودیافتگان-به-کرونا-وجود-دارد\thealth\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990814000825/رضایی-نیازمند-رویکرد-اقلیمی-و-محله‌ای-برای-مقابله-با-کرونا-هستیم\thealth\n",
            "-----\n",
            "https://www.farsnews.ir/news/13990727000856/بسته‌های-یخ-زده-غذایی-هم-می‌توانند-ناقل-کرونا-باشند\thealth\n",
            "-----\n",
            "https://www.farsnews.ir/news/13991215000426/عدم-رعایت-پروتکل‌های-بهداشتی-یعنی-تحمل-خسارت‌های-اقتصادی-و-معیشتی\thealth\n",
            "-----\n",
            "https://www.isna.ir/news/98113022846/کرونا-ویروس-جدید-چگونه-منتقل-می-شود\thealth\n",
            "-----\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "for res, q in zip(query_results, queries):\n",
        "    print(q)\n",
        "    for doc in res['hits']['hits']:\n",
        "        print('{}\\t{}'.format(doc['_source']['url'], doc['_source']['category']))\n",
        "        print('-----')\n",
        "    print(\"----------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of knn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "f56a879a86e4cb184598e0f1a037d80ac9bf804487d5cf89fe943b503a6b43f5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
